{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62997, 79)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>followers_count_mean</th>\n",
       "      <th>followers_count_median</th>\n",
       "      <th>followers_count_min</th>\n",
       "      <th>followers_count_max</th>\n",
       "      <th>friends_count_mean</th>\n",
       "      <th>friends_count_median</th>\n",
       "      <th>friends_count_min</th>\n",
       "      <th>friends_count_max</th>\n",
       "      <th>listed_count_mean</th>\n",
       "      <th>listed_count_median</th>\n",
       "      <th>...</th>\n",
       "      <th>number_of_photos_min</th>\n",
       "      <th>number_of_photos_max</th>\n",
       "      <th>number_of_urls_mean</th>\n",
       "      <th>number_of_urls_median</th>\n",
       "      <th>number_of_urls_min</th>\n",
       "      <th>number_of_urls_max</th>\n",
       "      <th>has_nft</th>\n",
       "      <th>has_crypto</th>\n",
       "      <th>number_of_tweets</th>\n",
       "      <th>permalink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>334.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>334</td>\n",
       "      <td>334</td>\n",
       "      <td>1368.0</td>\n",
       "      <td>1368.0</td>\n",
       "      <td>1368</td>\n",
       "      <td>1368</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>https://opensea.io/assets/0x005c1cfc36e5ec711b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2901.0</td>\n",
       "      <td>2901.0</td>\n",
       "      <td>2901</td>\n",
       "      <td>2901</td>\n",
       "      <td>3027.0</td>\n",
       "      <td>3027.0</td>\n",
       "      <td>3027</td>\n",
       "      <td>3027</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>https://opensea.io/assets/0x005c1cfc36e5ec711b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1627.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>1627</td>\n",
       "      <td>1627</td>\n",
       "      <td>908.0</td>\n",
       "      <td>908.0</td>\n",
       "      <td>908</td>\n",
       "      <td>908</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>https://opensea.io/assets/0x005efb3633638dd0dd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>https://opensea.io/assets/0x0076b645920716be2a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>215.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>215</td>\n",
       "      <td>215</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>https://opensea.io/assets/0x00c719960bfcb4286d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   followers_count_mean  followers_count_median  followers_count_min  \\\n",
       "0                 334.0                   334.0                  334   \n",
       "1                2901.0                  2901.0                 2901   \n",
       "2                1627.0                  1627.0                 1627   \n",
       "3                  76.0                    76.0                   76   \n",
       "4                  47.0                    47.0                   47   \n",
       "\n",
       "   followers_count_max  friends_count_mean  friends_count_median  \\\n",
       "0                  334              1368.0                1368.0   \n",
       "1                 2901              3027.0                3027.0   \n",
       "2                 1627               908.0                 908.0   \n",
       "3                   76                20.0                  20.0   \n",
       "4                   47               215.0                 215.0   \n",
       "\n",
       "   friends_count_min  friends_count_max  listed_count_mean  \\\n",
       "0               1368               1368                2.0   \n",
       "1               3027               3027               19.0   \n",
       "2                908                908               16.0   \n",
       "3                 20                 20                1.0   \n",
       "4                215                215                4.0   \n",
       "\n",
       "   listed_count_median  ...  number_of_photos_min  number_of_photos_max  \\\n",
       "0                  2.0  ...                     0                     0   \n",
       "1                 19.0  ...                     0                     0   \n",
       "2                 16.0  ...                     0                     0   \n",
       "3                  1.0  ...                     0                     0   \n",
       "4                  4.0  ...                     0                     0   \n",
       "\n",
       "   number_of_urls_mean  number_of_urls_median  number_of_urls_min  \\\n",
       "0                  1.0                    1.0                   1   \n",
       "1                  1.0                    1.0                   1   \n",
       "2                  1.0                    1.0                   1   \n",
       "3                  1.0                    1.0                   1   \n",
       "4                  1.0                    1.0                   1   \n",
       "\n",
       "   number_of_urls_max  has_nft  has_crypto  number_of_tweets  \\\n",
       "0                   1        0           0                 1   \n",
       "1                   1        0           0                 1   \n",
       "2                   1        0           0                 2   \n",
       "3                   1        0           0                 1   \n",
       "4                   1        0           0                 1   \n",
       "\n",
       "                                           permalink  \n",
       "0  https://opensea.io/assets/0x005c1cfc36e5ec711b...  \n",
       "1  https://opensea.io/assets/0x005c1cfc36e5ec711b...  \n",
       "2  https://opensea.io/assets/0x005efb3633638dd0dd...  \n",
       "3  https://opensea.io/assets/0x0076b645920716be2a...  \n",
       "4  https://opensea.io/assets/0x00c719960bfcb4286d...  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter = pd.read_csv('data/twitter_data.csv' , index_col=None, header=0, lineterminator='\\n')\n",
    "print(twitter.shape)\n",
    "twitter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62997, 47)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permalink</th>\n",
       "      <th>sell_orders</th>\n",
       "      <th>top_bid</th>\n",
       "      <th>listing_date</th>\n",
       "      <th>is_presale</th>\n",
       "      <th>transfer_fee</th>\n",
       "      <th>supports_wyvern</th>\n",
       "      <th>numEvents</th>\n",
       "      <th>transfer</th>\n",
       "      <th>successful</th>\n",
       "      <th>...</th>\n",
       "      <th>market_cap</th>\n",
       "      <th>floor_price</th>\n",
       "      <th>is_collection_verified</th>\n",
       "      <th>is_subject_to_whitelist</th>\n",
       "      <th>collection_name</th>\n",
       "      <th>creation_day</th>\n",
       "      <th>creation_month</th>\n",
       "      <th>creation_year</th>\n",
       "      <th>price_label</th>\n",
       "      <th>sale_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://opensea.io/assets/0xc7e5e9434f4a71e6db...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.896410e+02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>971</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://opensea.io/assets/0x495f947276749ce646...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7291</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://opensea.io/assets/0x495f947276749ce646...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7291</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://opensea.io/assets/0xd07dc4262bcdbf8519...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.827521e+15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11248</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://opensea.io/assets/0xd07dc4262bcdbf8519...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.838661e+15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11248</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           permalink  sell_orders  top_bid  \\\n",
       "0  https://opensea.io/assets/0xc7e5e9434f4a71e6db...          0.0      0.0   \n",
       "1  https://opensea.io/assets/0x495f947276749ce646...          0.0      0.0   \n",
       "2  https://opensea.io/assets/0x495f947276749ce646...          0.0      0.0   \n",
       "3  https://opensea.io/assets/0xd07dc4262bcdbf8519...          0.0      0.0   \n",
       "5  https://opensea.io/assets/0xd07dc4262bcdbf8519...          0.0      0.0   \n",
       "\n",
       "   listing_date  is_presale  transfer_fee  supports_wyvern  numEvents  \\\n",
       "0           0.0           0           0.0                1          1   \n",
       "1           0.0           1           0.0                1          1   \n",
       "2           0.0           1           0.0                1          1   \n",
       "3           0.0           0           0.0                1          6   \n",
       "5           0.0           0           0.0                1          2   \n",
       "\n",
       "   transfer  successful  ...    market_cap  floor_price  \\\n",
       "0         1           0  ...  2.896410e+02            0   \n",
       "1         1           0  ...  0.000000e+00            0   \n",
       "2         1           0  ...  0.000000e+00            0   \n",
       "3         1           0  ...  3.827521e+15            0   \n",
       "5         2           0  ...  2.838661e+15            0   \n",
       "\n",
       "   is_collection_verified  is_subject_to_whitelist  collection_name  \\\n",
       "0                       1                        0              971   \n",
       "1                       0                        0             7291   \n",
       "2                       0                        0             7291   \n",
       "3                       1                        0            11248   \n",
       "5                       1                        0            11248   \n",
       "\n",
       "   creation_day  creation_month  creation_year  price_label  sale_label  \n",
       "0             2               1           2021            0           0  \n",
       "1             2               1           2021            0           0  \n",
       "2             3               1           2021            0           0  \n",
       "3             3               1           2021            0           0  \n",
       "5             2               1           2021            0           0  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opensea = pd.read_csv('data/opensea_data.csv' , index_col=0, header=0, lineterminator='\\n')\n",
    "print(opensea.shape)\n",
    "opensea.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62997, 125)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>followers_count_mean</th>\n",
       "      <th>followers_count_median</th>\n",
       "      <th>followers_count_min</th>\n",
       "      <th>followers_count_max</th>\n",
       "      <th>friends_count_mean</th>\n",
       "      <th>friends_count_median</th>\n",
       "      <th>friends_count_min</th>\n",
       "      <th>friends_count_max</th>\n",
       "      <th>listed_count_mean</th>\n",
       "      <th>listed_count_median</th>\n",
       "      <th>...</th>\n",
       "      <th>market_cap</th>\n",
       "      <th>floor_price</th>\n",
       "      <th>is_collection_verified</th>\n",
       "      <th>is_subject_to_whitelist</th>\n",
       "      <th>collection_name</th>\n",
       "      <th>creation_day</th>\n",
       "      <th>creation_month</th>\n",
       "      <th>creation_year</th>\n",
       "      <th>price_label</th>\n",
       "      <th>sale_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>334.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>334</td>\n",
       "      <td>334</td>\n",
       "      <td>1368.0</td>\n",
       "      <td>1368.0</td>\n",
       "      <td>1368</td>\n",
       "      <td>1368</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4818</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2901.0</td>\n",
       "      <td>2901.0</td>\n",
       "      <td>2901</td>\n",
       "      <td>2901</td>\n",
       "      <td>3027.0</td>\n",
       "      <td>3027.0</td>\n",
       "      <td>3027</td>\n",
       "      <td>3027</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4818</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1627.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>1627</td>\n",
       "      <td>1627</td>\n",
       "      <td>908.0</td>\n",
       "      <td>908.0</td>\n",
       "      <td>908</td>\n",
       "      <td>908</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12051</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12410</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>215.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>215</td>\n",
       "      <td>215</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7921</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   followers_count_mean  followers_count_median  followers_count_min  \\\n",
       "0                 334.0                   334.0                  334   \n",
       "1                2901.0                  2901.0                 2901   \n",
       "2                1627.0                  1627.0                 1627   \n",
       "3                  76.0                    76.0                   76   \n",
       "4                  47.0                    47.0                   47   \n",
       "\n",
       "   followers_count_max  friends_count_mean  friends_count_median  \\\n",
       "0                  334              1368.0                1368.0   \n",
       "1                 2901              3027.0                3027.0   \n",
       "2                 1627               908.0                 908.0   \n",
       "3                   76                20.0                  20.0   \n",
       "4                   47               215.0                 215.0   \n",
       "\n",
       "   friends_count_min  friends_count_max  listed_count_mean  \\\n",
       "0               1368               1368                2.0   \n",
       "1               3027               3027               19.0   \n",
       "2                908                908               16.0   \n",
       "3                 20                 20                1.0   \n",
       "4                215                215                4.0   \n",
       "\n",
       "   listed_count_median  ...  market_cap  floor_price  is_collection_verified  \\\n",
       "0                  2.0  ...         0.0            0                       1   \n",
       "1                 19.0  ...         0.0            0                       1   \n",
       "2                 16.0  ...         0.0            0                       1   \n",
       "3                  1.0  ...         0.0            0                       0   \n",
       "4                  4.0  ...         0.0            0                       0   \n",
       "\n",
       "   is_subject_to_whitelist  collection_name  creation_day  creation_month  \\\n",
       "0                        0             4818            23               3   \n",
       "1                        0             4818            23               3   \n",
       "2                        0            12051             5               1   \n",
       "3                        0            12410            26               3   \n",
       "4                        0             7921            17               3   \n",
       "\n",
       "   creation_year  price_label  sale_label  \n",
       "0           2021            0           0  \n",
       "1           2021            0           0  \n",
       "2           2021            4           1  \n",
       "3           2021            0           0  \n",
       "4           2021            3           1  \n",
       "\n",
       "[5 rows x 125 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = twitter.merge(opensea, on='permalink')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling only with twitter data\n",
    "\n",
    "This will allow for a comparison with a model containing all features. \n",
    "\n",
    "We then drop opensea features but we keep price_label column which is our target and the reason why we merge both datasets in the first place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = opensea.columns.tolist()\n",
    "to_drop.remove('price_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62997, 79)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>followers_count_mean</th>\n",
       "      <th>followers_count_median</th>\n",
       "      <th>followers_count_min</th>\n",
       "      <th>followers_count_max</th>\n",
       "      <th>friends_count_mean</th>\n",
       "      <th>friends_count_median</th>\n",
       "      <th>friends_count_min</th>\n",
       "      <th>friends_count_max</th>\n",
       "      <th>listed_count_mean</th>\n",
       "      <th>listed_count_median</th>\n",
       "      <th>...</th>\n",
       "      <th>number_of_photos_min</th>\n",
       "      <th>number_of_photos_max</th>\n",
       "      <th>number_of_urls_mean</th>\n",
       "      <th>number_of_urls_median</th>\n",
       "      <th>number_of_urls_min</th>\n",
       "      <th>number_of_urls_max</th>\n",
       "      <th>has_nft</th>\n",
       "      <th>has_crypto</th>\n",
       "      <th>number_of_tweets</th>\n",
       "      <th>price_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>334.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>334</td>\n",
       "      <td>334</td>\n",
       "      <td>1368.0</td>\n",
       "      <td>1368.0</td>\n",
       "      <td>1368</td>\n",
       "      <td>1368</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2901.0</td>\n",
       "      <td>2901.0</td>\n",
       "      <td>2901</td>\n",
       "      <td>2901</td>\n",
       "      <td>3027.0</td>\n",
       "      <td>3027.0</td>\n",
       "      <td>3027</td>\n",
       "      <td>3027</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1627.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>1627</td>\n",
       "      <td>1627</td>\n",
       "      <td>908.0</td>\n",
       "      <td>908.0</td>\n",
       "      <td>908</td>\n",
       "      <td>908</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>215.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>215</td>\n",
       "      <td>215</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   followers_count_mean  followers_count_median  followers_count_min  \\\n",
       "0                 334.0                   334.0                  334   \n",
       "1                2901.0                  2901.0                 2901   \n",
       "2                1627.0                  1627.0                 1627   \n",
       "3                  76.0                    76.0                   76   \n",
       "4                  47.0                    47.0                   47   \n",
       "\n",
       "   followers_count_max  friends_count_mean  friends_count_median  \\\n",
       "0                  334              1368.0                1368.0   \n",
       "1                 2901              3027.0                3027.0   \n",
       "2                 1627               908.0                 908.0   \n",
       "3                   76                20.0                  20.0   \n",
       "4                   47               215.0                 215.0   \n",
       "\n",
       "   friends_count_min  friends_count_max  listed_count_mean  \\\n",
       "0               1368               1368                2.0   \n",
       "1               3027               3027               19.0   \n",
       "2                908                908               16.0   \n",
       "3                 20                 20                1.0   \n",
       "4                215                215                4.0   \n",
       "\n",
       "   listed_count_median  ...  number_of_photos_min  number_of_photos_max  \\\n",
       "0                  2.0  ...                     0                     0   \n",
       "1                 19.0  ...                     0                     0   \n",
       "2                 16.0  ...                     0                     0   \n",
       "3                  1.0  ...                     0                     0   \n",
       "4                  4.0  ...                     0                     0   \n",
       "\n",
       "   number_of_urls_mean  number_of_urls_median  number_of_urls_min  \\\n",
       "0                  1.0                    1.0                   1   \n",
       "1                  1.0                    1.0                   1   \n",
       "2                  1.0                    1.0                   1   \n",
       "3                  1.0                    1.0                   1   \n",
       "4                  1.0                    1.0                   1   \n",
       "\n",
       "   number_of_urls_max  has_nft  has_crypto  number_of_tweets  price_label  \n",
       "0                   1        0           0                 1            0  \n",
       "1                   1        0           0                 1            0  \n",
       "2                   1        0           0                 2            4  \n",
       "3                   1        0           0                 1            0  \n",
       "4                   1        0           0                 1            3  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(to_drop,axis=1,inplace=True)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't have missing values as we handle data quality during the data acquisition step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>percent_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [column_name, percent_missing]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_missing = df.isnull().sum() * 100 / len(df)\n",
    "missing_value_df = pd.DataFrame({'column_name': df.columns,\n",
    "                                 'percent_missing': percent_missing})\n",
    "missing_value_df.sort_values('percent_missing', inplace=True)\n",
    "missing_value_df.reset_index(drop=True)\n",
    "full_missing_value_df = missing_value_df[missing_value_df['percent_missing'] > 0 ]\n",
    "full_missing_value_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no categorical variables to handle because twitter dataset is made of counts and other aggregations statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    43\n",
       "int64      36\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification step\n",
    "\n",
    "Here, we use a tree based model that is known to be very effective for this kind of tasks. Hence, we don't need to handle multicolinearity, outliers and normalization fo the data. H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1500\n",
       "1    1500\n",
       "2    1500\n",
       "3    1500\n",
       "4     234\n",
       "Name: price_label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 1500 \n",
    "\n",
    "df.loc[df['price_label'] == 5] = 4\n",
    "df_subsampled0 = df[df['price_label'] == 4]\n",
    "df_subsampled1 = df[df['price_label'] == 0].sample(n=n, random_state=0)\n",
    "df_subsampled2 = df[df['price_label'] == 1].sample(n=n, random_state=0)\n",
    "df_subsampled3 = df[df['price_label'] == 2].sample(n=n, random_state=0)\n",
    "df_subsampled4 = df[df['price_label'] == 3].sample(n=n, random_state=0)\n",
    "\n",
    "df_concatenated = pd.concat([df_subsampled0, df_subsampled1, df_subsampled2, df_subsampled3, df_subsampled4])\n",
    "df_concatenated['price_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the target\n",
    "X = df_concatenated.drop(['price_label', 'avg_selling_price'],axis=1)\n",
    "y = df_concatenated.price_label\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Balance the classes \n",
    "\n",
    "First we have to manually subsample the majority class and then we can use an algorithm.\n",
    "\n",
    "ADASYN (Adaptive Synthetic Sampling) is a type of oversampling technique for imbalanced datasets. Unlike traditional oversampling techniques like SMOTE which oversamples the minority class with a fixed ratio, ADASYN dynamically adjusts the oversampling ratio for minority samples based on their difficulty in being classified.\n",
    "\n",
    "The idea behind ADASYN is to oversample the minority samples that are difficult to be classified correctly. These samples are usually located near the decision boundary between classes and may cause the classifier to be biased towards the majority class. By oversampling these samples, the classifier can be trained to better handle the minority class.\n",
    "\n",
    "In ADASYN, a density distribution is calculated for the minority samples based on their distances to their k-nearest neighbors. The samples with higher density are more likely to be oversampled. This way, the oversampling ratio is adjusted based on the difficulty of the minority samples, rather than a fixed ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    1200\n",
       "1    1200\n",
       "3    1200\n",
       "0    1200\n",
       "4     187\n",
       "Name: price_label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    1246\n",
       "2    1200\n",
       "1    1200\n",
       "3    1200\n",
       "0    1200\n",
       "Name: price_label, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "adasyn = ADASYN(sampling_strategy='minority', random_state=0)\n",
    "X_resampled, y_resampled = adasyn.fit_resample(X_train, y_train)\n",
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=LGBMClassifier(), n_iter=30, n_jobs=-1,\n",
       "                   param_distributions={'boosting_type': ['gbdt'],\n",
       "                                        'learning_rate': [0.05, 0.1, 0.15, 0.2,\n",
       "                                                          0.5],\n",
       "                                        'min_child_samples': [10, 20, 30, 40],\n",
       "                                        'n_estimators': [50, 100, 200, 500],\n",
       "                                        'num_leaves': [32, 64, 128, 256],\n",
       "                                        'objective': ['binary'],\n",
       "                                        'verbose': [-1]},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "clf = lgb.LGBMClassifier()\n",
    "        \n",
    "# Random Search for Hyperparameters\n",
    "param_grid = {\n",
    "    'boosting_type': ['gbdt'],\n",
    "    'objective': ['binary'],\n",
    "    'num_leaves': [32, 64, 128, 256],\n",
    "    'learning_rate': [0.05, 0.1, 0.15, 0.2, 0.5],\n",
    "    'min_child_samples': [10, 20, 30, 40],\n",
    "    'n_estimators': [50, 100, 200, 500],\n",
    "    'verbose': [-1]\n",
    "    }\n",
    "\n",
    "clf_random = RandomizedSearchCV(estimator = clf, param_distributions = param_grid, n_iter = 30, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "clf_random.fit(X_resampled, y_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': -1,\n",
       " 'objective': 'binary',\n",
       " 'num_leaves': 64,\n",
       " 'n_estimators': 500,\n",
       " 'min_child_samples': 10,\n",
       " 'learning_rate': 0.1,\n",
       " 'boosting_type': 'gbdt'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best hyperparameters\n",
    "best_clf = clf_random.best_estimator_\n",
    "\n",
    "# Predict the target using the best classifier\n",
    "y_pred = best_clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5517241379310345\n",
      "Precision: 0.5201577506332878\n",
      "Recall: 0.48737588652482267\n",
      "F1 Score: 0.4950800293184171 \n",
      "\n",
      "Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.554     0.637     0.592       300\n",
      "           1      0.572     0.553     0.563       300\n",
      "           2      0.503     0.500     0.502       300\n",
      "           3      0.590     0.577     0.583       300\n",
      "           4      0.381     0.170     0.235        47\n",
      "\n",
      "    accuracy                          0.552      1247\n",
      "   macro avg      0.520     0.487     0.495      1247\n",
      "weighted avg      0.548     0.552     0.548      1247\n",
      "\n",
      "[CV] verbose=-1, objective=binary, num_leaves=64, n_estimators=200, min_child_samples=10, learning_rate=0.05, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=64, n_estimators=200, min_child_samples=10, learning_rate=0.05, boosting_type=gbdt, total=  13.1s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=32, n_estimators=50, min_child_samples=30, learning_rate=0.2, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=32, n_estimators=50, min_child_samples=30, learning_rate=0.2, boosting_type=gbdt, total=   1.7s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=32, n_estimators=50, min_child_samples=30, learning_rate=0.2, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=32, n_estimators=50, min_child_samples=30, learning_rate=0.2, boosting_type=gbdt, total=   2.3s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=128, n_estimators=200, min_child_samples=20, learning_rate=0.1, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=128, n_estimators=200, min_child_samples=20, learning_rate=0.1, boosting_type=gbdt, total=  18.9s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=256, n_estimators=100, min_child_samples=40, learning_rate=0.05, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=256, n_estimators=100, min_child_samples=40, learning_rate=0.05, boosting_type=gbdt, total=   6.0s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=256, n_estimators=200, min_child_samples=10, learning_rate=0.2, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=256, n_estimators=200, min_child_samples=10, learning_rate=0.2, boosting_type=gbdt, total=  13.6s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=64, n_estimators=200, min_child_samples=30, learning_rate=0.5, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=64, n_estimators=200, min_child_samples=30, learning_rate=0.5, boosting_type=gbdt, total=   5.7s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=128, n_estimators=100, min_child_samples=30, learning_rate=0.2, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=128, n_estimators=100, min_child_samples=30, learning_rate=0.2, boosting_type=gbdt, total=   7.6s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=128, n_estimators=200, min_child_samples=40, learning_rate=0.15, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=128, n_estimators=200, min_child_samples=40, learning_rate=0.15, boosting_type=gbdt, total=  12.9s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=128, n_estimators=50, min_child_samples=20, learning_rate=0.1, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=128, n_estimators=50, min_child_samples=20, learning_rate=0.1, boosting_type=gbdt, total=   5.4s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=128, n_estimators=50, min_child_samples=20, learning_rate=0.1, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=128, n_estimators=50, min_child_samples=20, learning_rate=0.1, boosting_type=gbdt, total=   5.1s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=32, n_estimators=50, min_child_samples=40, learning_rate=0.2, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=32, n_estimators=50, min_child_samples=40, learning_rate=0.2, boosting_type=gbdt, total=   1.6s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=256, n_estimators=100, min_child_samples=40, learning_rate=0.1, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=256, n_estimators=100, min_child_samples=40, learning_rate=0.1, boosting_type=gbdt, total=   6.4s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=32, n_estimators=200, min_child_samples=30, learning_rate=0.1, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=32, n_estimators=200, min_child_samples=30, learning_rate=0.1, boosting_type=gbdt, total=   6.5s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=128, n_estimators=100, min_child_samples=10, learning_rate=0.2, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=128, n_estimators=100, min_child_samples=10, learning_rate=0.2, boosting_type=gbdt, total=  10.0s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=64, n_estimators=200, min_child_samples=30, learning_rate=0.5, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=64, n_estimators=200, min_child_samples=30, learning_rate=0.5, boosting_type=gbdt, total=   6.1s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=128, n_estimators=100, min_child_samples=30, learning_rate=0.2, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=128, n_estimators=100, min_child_samples=30, learning_rate=0.2, boosting_type=gbdt, total=   7.5s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=128, n_estimators=500, min_child_samples=30, learning_rate=0.1, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=128, n_estimators=500, min_child_samples=30, learning_rate=0.1, boosting_type=gbdt, total=  27.8s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=256, n_estimators=100, min_child_samples=40, learning_rate=0.05, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=256, n_estimators=100, min_child_samples=40, learning_rate=0.05, boosting_type=gbdt, total=   6.1s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=256, n_estimators=200, min_child_samples=10, learning_rate=0.2, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=256, n_estimators=200, min_child_samples=10, learning_rate=0.2, boosting_type=gbdt, total=  13.5s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=64, n_estimators=100, min_child_samples=20, learning_rate=0.2, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=64, n_estimators=100, min_child_samples=20, learning_rate=0.2, boosting_type=gbdt, total=   6.8s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=64, n_estimators=200, min_child_samples=10, learning_rate=0.05, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=64, n_estimators=200, min_child_samples=10, learning_rate=0.05, boosting_type=gbdt, total=  12.4s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=32, n_estimators=100, min_child_samples=40, learning_rate=0.2, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=32, n_estimators=100, min_child_samples=40, learning_rate=0.2, boosting_type=gbdt, total=   3.4s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=128, n_estimators=200, min_child_samples=20, learning_rate=0.1, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=128, n_estimators=200, min_child_samples=20, learning_rate=0.1, boosting_type=gbdt, total=  18.6s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=128, n_estimators=200, min_child_samples=10, learning_rate=0.2, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=128, n_estimators=200, min_child_samples=10, learning_rate=0.2, boosting_type=gbdt, total=  11.5s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=128, n_estimators=100, min_child_samples=10, learning_rate=0.2, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=128, n_estimators=100, min_child_samples=10, learning_rate=0.2, boosting_type=gbdt, total=  10.2s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=64, n_estimators=200, min_child_samples=30, learning_rate=0.5, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=64, n_estimators=200, min_child_samples=30, learning_rate=0.5, boosting_type=gbdt, total=   6.4s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=64, n_estimators=200, min_child_samples=20, learning_rate=0.05, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=64, n_estimators=200, min_child_samples=20, learning_rate=0.05, boosting_type=gbdt, total=  11.4s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=256, n_estimators=500, min_child_samples=10, learning_rate=0.15, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=256, n_estimators=500, min_child_samples=10, learning_rate=0.15, boosting_type=gbdt, total=  23.2s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=128, n_estimators=200, min_child_samples=10, learning_rate=0.2, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=128, n_estimators=200, min_child_samples=10, learning_rate=0.2, boosting_type=gbdt, total=  11.5s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=256, n_estimators=200, min_child_samples=10, learning_rate=0.15, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=256, n_estimators=200, min_child_samples=10, learning_rate=0.15, boosting_type=gbdt, total=  17.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] verbose=-1, objective=binary, num_leaves=128, n_estimators=100, min_child_samples=30, learning_rate=0.2, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=128, n_estimators=100, min_child_samples=30, learning_rate=0.2, boosting_type=gbdt, total=   7.6s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=128, n_estimators=500, min_child_samples=30, learning_rate=0.1, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=128, n_estimators=500, min_child_samples=30, learning_rate=0.1, boosting_type=gbdt, total=  25.9s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=256, n_estimators=100, min_child_samples=40, learning_rate=0.1, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=256, n_estimators=100, min_child_samples=40, learning_rate=0.1, boosting_type=gbdt, total=   6.3s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=32, n_estimators=200, min_child_samples=30, learning_rate=0.1, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=32, n_estimators=200, min_child_samples=30, learning_rate=0.1, boosting_type=gbdt, total=   6.2s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=256, n_estimators=200, min_child_samples=10, learning_rate=0.15, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=256, n_estimators=200, min_child_samples=10, learning_rate=0.15, boosting_type=gbdt, total=  18.0s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=256, n_estimators=100, min_child_samples=30, learning_rate=0.15, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=256, n_estimators=100, min_child_samples=30, learning_rate=0.15, boosting_type=gbdt, total=   8.1s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=256, n_estimators=500, min_child_samples=10, learning_rate=0.15, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=256, n_estimators=500, min_child_samples=10, learning_rate=0.15, boosting_type=gbdt, total=  22.8s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=32, n_estimators=50, min_child_samples=40, learning_rate=0.2, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=32, n_estimators=50, min_child_samples=40, learning_rate=0.2, boosting_type=gbdt, total=   1.7s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=32, n_estimators=500, min_child_samples=30, learning_rate=0.15, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=32, n_estimators=500, min_child_samples=30, learning_rate=0.15, boosting_type=gbdt, total=  14.5s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=128, n_estimators=200, min_child_samples=30, learning_rate=0.05, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=128, n_estimators=200, min_child_samples=30, learning_rate=0.05, boosting_type=gbdt, total=  17.3s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=256, n_estimators=500, min_child_samples=40, learning_rate=0.05, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=256, n_estimators=500, min_child_samples=40, learning_rate=0.05, boosting_type=gbdt, total=  34.3s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=256, n_estimators=100, min_child_samples=40, learning_rate=0.1, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=256, n_estimators=100, min_child_samples=40, learning_rate=0.1, boosting_type=gbdt, total=   6.1s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=256, n_estimators=200, min_child_samples=10, learning_rate=0.2, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=256, n_estimators=200, min_child_samples=10, learning_rate=0.2, boosting_type=gbdt, total=  13.4s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=64, n_estimators=100, min_child_samples=20, learning_rate=0.2, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=64, n_estimators=100, min_child_samples=20, learning_rate=0.2, boosting_type=gbdt, total=   6.7s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=256, n_estimators=100, min_child_samples=40, learning_rate=0.15, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=256, n_estimators=100, min_child_samples=40, learning_rate=0.15, boosting_type=gbdt, total=   4.1s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=256, n_estimators=500, min_child_samples=40, learning_rate=0.05, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=256, n_estimators=500, min_child_samples=40, learning_rate=0.05, boosting_type=gbdt, total=  32.4s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=32, n_estimators=500, min_child_samples=30, learning_rate=0.15, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=32, n_estimators=500, min_child_samples=30, learning_rate=0.15, boosting_type=gbdt, total=  14.4s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=256, n_estimators=200, min_child_samples=10, learning_rate=0.15, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=256, n_estimators=200, min_child_samples=10, learning_rate=0.15, boosting_type=gbdt, total=  18.0s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=64, n_estimators=200, min_child_samples=20, learning_rate=0.05, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=64, n_estimators=200, min_child_samples=20, learning_rate=0.05, boosting_type=gbdt, total=  11.2s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=256, n_estimators=500, min_child_samples=10, learning_rate=0.15, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=256, n_estimators=500, min_child_samples=10, learning_rate=0.15, boosting_type=gbdt, total=  23.7s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=64, n_estimators=500, min_child_samples=10, learning_rate=0.1, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=64, n_estimators=500, min_child_samples=10, learning_rate=0.1, boosting_type=gbdt, total=  23.0s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=64, n_estimators=50, min_child_samples=30, learning_rate=0.05, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=64, n_estimators=50, min_child_samples=30, learning_rate=0.05, boosting_type=gbdt, total=   3.2s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=256, n_estimators=100, min_child_samples=40, learning_rate=0.15, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=256, n_estimators=100, min_child_samples=40, learning_rate=0.15, boosting_type=gbdt, total=   3.8s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=256, n_estimators=100, min_child_samples=30, learning_rate=0.15, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=256, n_estimators=100, min_child_samples=30, learning_rate=0.15, boosting_type=gbdt, total=   7.8s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=128, n_estimators=200, min_child_samples=40, learning_rate=0.15, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=128, n_estimators=200, min_child_samples=40, learning_rate=0.15, boosting_type=gbdt, total=  12.2s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=32, n_estimators=500, min_child_samples=10, learning_rate=0.1, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=32, n_estimators=500, min_child_samples=10, learning_rate=0.1, boosting_type=gbdt, total=  17.9s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=256, n_estimators=100, min_child_samples=40, learning_rate=0.05, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=256, n_estimators=100, min_child_samples=40, learning_rate=0.05, boosting_type=gbdt, total=   6.0s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=256, n_estimators=50, min_child_samples=20, learning_rate=0.2, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=256, n_estimators=50, min_child_samples=20, learning_rate=0.2, boosting_type=gbdt, total=   6.3s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=128, n_estimators=200, min_child_samples=30, learning_rate=0.05, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=128, n_estimators=200, min_child_samples=30, learning_rate=0.05, boosting_type=gbdt, total=  15.4s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=128, n_estimators=500, min_child_samples=30, learning_rate=0.1, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=128, n_estimators=500, min_child_samples=30, learning_rate=0.1, boosting_type=gbdt, total=  24.5s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=128, n_estimators=50, min_child_samples=20, learning_rate=0.1, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=128, n_estimators=50, min_child_samples=20, learning_rate=0.1, boosting_type=gbdt, total=   5.2s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=32, n_estimators=50, min_child_samples=40, learning_rate=0.2, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=32, n_estimators=50, min_child_samples=40, learning_rate=0.2, boosting_type=gbdt, total=   1.7s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=32, n_estimators=500, min_child_samples=30, learning_rate=0.15, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=32, n_estimators=500, min_child_samples=30, learning_rate=0.15, boosting_type=gbdt, total=  13.8s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=256, n_estimators=50, min_child_samples=20, learning_rate=0.2, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=256, n_estimators=50, min_child_samples=20, learning_rate=0.2, boosting_type=gbdt, total=   6.2s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=64, n_estimators=100, min_child_samples=20, learning_rate=0.2, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=64, n_estimators=100, min_child_samples=20, learning_rate=0.2, boosting_type=gbdt, total=   6.3s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=64, n_estimators=50, min_child_samples=30, learning_rate=0.05, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=64, n_estimators=50, min_child_samples=30, learning_rate=0.05, boosting_type=gbdt, total=   3.6s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=256, n_estimators=100, min_child_samples=40, learning_rate=0.15, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=256, n_estimators=100, min_child_samples=40, learning_rate=0.15, boosting_type=gbdt, total=   4.4s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=256, n_estimators=100, min_child_samples=30, learning_rate=0.15, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=256, n_estimators=100, min_child_samples=30, learning_rate=0.15, boosting_type=gbdt, total=   7.8s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=128, n_estimators=200, min_child_samples=40, learning_rate=0.15, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=128, n_estimators=200, min_child_samples=40, learning_rate=0.15, boosting_type=gbdt, total=  12.7s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=32, n_estimators=500, min_child_samples=10, learning_rate=0.1, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=32, n_estimators=500, min_child_samples=10, learning_rate=0.1, boosting_type=gbdt, total=  17.8s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=32, n_estimators=200, min_child_samples=30, learning_rate=0.1, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=32, n_estimators=200, min_child_samples=30, learning_rate=0.1, boosting_type=gbdt, total=   6.5s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=256, n_estimators=50, min_child_samples=20, learning_rate=0.2, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=256, n_estimators=50, min_child_samples=20, learning_rate=0.2, boosting_type=gbdt, total=   6.3s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=128, n_estimators=200, min_child_samples=30, learning_rate=0.05, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=128, n_estimators=200, min_child_samples=30, learning_rate=0.05, boosting_type=gbdt, total=  14.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] verbose=-1, objective=binary, num_leaves=64, n_estimators=200, min_child_samples=20, learning_rate=0.05, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=64, n_estimators=200, min_child_samples=20, learning_rate=0.05, boosting_type=gbdt, total=  11.7s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=32, n_estimators=100, min_child_samples=40, learning_rate=0.2, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=32, n_estimators=100, min_child_samples=40, learning_rate=0.2, boosting_type=gbdt, total=   3.9s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=32, n_estimators=50, min_child_samples=30, learning_rate=0.2, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=32, n_estimators=50, min_child_samples=30, learning_rate=0.2, boosting_type=gbdt, total=   2.1s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=32, n_estimators=500, min_child_samples=10, learning_rate=0.1, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=32, n_estimators=500, min_child_samples=10, learning_rate=0.1, boosting_type=gbdt, total=  17.4s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=64, n_estimators=500, min_child_samples=10, learning_rate=0.1, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=64, n_estimators=500, min_child_samples=10, learning_rate=0.1, boosting_type=gbdt, total=  24.0s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=64, n_estimators=200, min_child_samples=10, learning_rate=0.1, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=64, n_estimators=200, min_child_samples=10, learning_rate=0.1, boosting_type=gbdt, total=   7.7s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=64, n_estimators=200, min_child_samples=10, learning_rate=0.05, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=64, n_estimators=200, min_child_samples=10, learning_rate=0.05, boosting_type=gbdt, total=  12.4s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=32, n_estimators=100, min_child_samples=40, learning_rate=0.2, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=32, n_estimators=100, min_child_samples=40, learning_rate=0.2, boosting_type=gbdt, total=   3.5s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=128, n_estimators=200, min_child_samples=20, learning_rate=0.1, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=128, n_estimators=200, min_child_samples=20, learning_rate=0.1, boosting_type=gbdt, total=  19.1s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=64, n_estimators=500, min_child_samples=10, learning_rate=0.1, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=64, n_estimators=500, min_child_samples=10, learning_rate=0.1, boosting_type=gbdt, total=  24.7s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=64, n_estimators=200, min_child_samples=10, learning_rate=0.1, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=64, n_estimators=200, min_child_samples=10, learning_rate=0.1, boosting_type=gbdt, total=   7.2s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=256, n_estimators=500, min_child_samples=40, learning_rate=0.05, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=256, n_estimators=500, min_child_samples=40, learning_rate=0.05, boosting_type=gbdt, total=  34.4s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=128, n_estimators=200, min_child_samples=10, learning_rate=0.2, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=128, n_estimators=200, min_child_samples=10, learning_rate=0.2, boosting_type=gbdt, total=  11.2s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=128, n_estimators=100, min_child_samples=10, learning_rate=0.2, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=128, n_estimators=100, min_child_samples=10, learning_rate=0.2, boosting_type=gbdt, total=  10.8s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=64, n_estimators=50, min_child_samples=30, learning_rate=0.05, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=64, n_estimators=50, min_child_samples=30, learning_rate=0.05, boosting_type=gbdt, total=   3.2s\n",
      "[CV] verbose=-1, objective=binary, num_leaves=64, n_estimators=200, min_child_samples=10, learning_rate=0.1, boosting_type=gbdt \n",
      "[CV]  verbose=-1, objective=binary, num_leaves=64, n_estimators=200, min_child_samples=10, learning_rate=0.1, boosting_type=gbdt, total=   8.1s\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Calculate the evaluation metrics \n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1, '\\n')\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\\n\\n\", classification_report(y_test , y_pred, digits=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: It is the number of correct predictions made by the model divided by the total number of predictions made. It gives a general idea of how many predictions the model got right, but can be misleading in cases where the classes are imbalanced.\n",
    "\n",
    "Precision: Precision is the number of true positive predictions made by the model divided by the total number of positive predictions made. Precision is a measure of how well the model avoids false positives (i.e., cases where the model predicted positive but was actually negative).\n",
    "\n",
    "Recall: Recall is the number of true positive predictions made by the model divided by the total number of actual positive cases. Recall is a measure of how well the model identifies positive cases (i.e., cases where the model predicted positive and was actually positive).\n",
    "\n",
    "F1-Score: The F1-score is the harmonic mean of precision and recall, which balances the trade-off between precision and recall. A high F1-score indicates a good balance between precision and recall.\n",
    "\n",
    "\n",
    "### Make predictions \n",
    "\n",
    "1. The predictions for each binary classifier are stored in the final_predictions list. \n",
    "\n",
    "2. The final_predictions list is then converted into a numpy array and the maximum predicted class for each data point is obtained using the argmax function. \n",
    "\n",
    "3. Finally, the predictions are converted into a single class label using the classes list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.854     0.951     0.900      9637\n",
      "           1      0.171     0.376     0.235       800\n",
      "           2      0.390     0.014     0.026      1678\n",
      "           3      0.429     0.007     0.013       438\n",
      "           4      0.200     0.024     0.043        42\n",
      "           5      0.000     0.000     0.000         5\n",
      "\n",
      "    accuracy                          0.754     12600\n",
      "   macro avg      0.341     0.229     0.203     12600\n",
      "weighted avg      0.731     0.754     0.707     12600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the binary classifiers\n",
    "with open(\"binary_classifiers.pickle\", \"wb\") as f:\n",
    "    pickle.dump(classifiers, f)\n",
    "\n",
    "# Later, when you want to make predictions\n",
    "# Load the binary classifiers\n",
    "with open(\"binary_classifiers.pickle\", \"rb\") as f:\n",
    "    classifiers = pickle.load(f)\n",
    "\n",
    "\n",
    "def make_predictions(classifiers, X_test): \n",
    "\n",
    "    # Use the trained classifiers to predict the class for each example\n",
    "    predictions = []\n",
    "    for i in range(len(classes) - 1):\n",
    "        # Predict the class for each example\n",
    "        p = classifiers[i].predict(X_test)\n",
    "        predictions.append(p)\n",
    "\n",
    "    # Convert the predictions into a single class label\n",
    "    final_predictions = []\n",
    "    for i in range(len(y_test)):\n",
    "        for j in range(len(classes) - 1):\n",
    "            if predictions[j][i] > 0.5:\n",
    "                final_predictions.append(classes[j+1])\n",
    "                break\n",
    "        else:\n",
    "            final_predictions.append(classes[0])\n",
    "    \n",
    "    return final_predictions\n",
    "\n",
    "\n",
    "# Make predictions using the binary classifiers\n",
    "final_predictions = make_predictions(classifiers, X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\\n\\n\", classification_report(y_test , final_predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
